fullnameOverride: ""
global:
  defaultStorageClass: ""
  defaultStorageSize: ""
nameOverride: ""
role:
  annotations: { }
roleBinding:
  annotations: { }
secret: { }
#  stringData:
#    AWS_ACCESS_KEY_ID: <aws-access-key-id>
#    AWS_REGION: eu-central-1
#    AWS_SECRET_ACCESS_KEY: <aws-secret-access-key>
service:
  enabled: true
  port: 80
  type: ClusterIP
serviceAccount:
  create: true
  automount: true
  annotations: { }
  name: ""
spec:
  affinity: { }
  annotations: { }
  # Overrides extraEnv:
  env: [ ]
  # Overrides extraEnvFrom:
  envFrom: [ ]
  extraEnv: [ ]
  extraEnvFrom: [ ]
  image:
    repository: apache/druid
    pull:
      policy: IfNotPresent
      secrets: [ ]
    tag: ""
  commonRuntimeProperties: { }
  deleteOrphanPvc: true
  disablePVCDeletionFinalizer: false
  extensions:
    org.apache.druid.extensions:
      - druid-datasketches
      - druid-kafka-extraction-namespace
      - druid-kafka-indexing-service
      - druid-kubernetes-extensions
      - druid-lookups-cached-global
      - druid-multi-stage-query
      - druid-s3-extensions
# One of these will be automatically added based on the value of metadataStorage.type:
#      - mysql-metadata-storage
#      - postgresql-metadata-storage
    org.apache.druid.extensions.contrib:
      - druid-kubernetes-overlord-extensions
  extraCommonConfig: [ ]
  jvmOptions:
    - -Dfile.encoding=UTF-8
    - -Djava.util.logging.manager=org.apache.logging.log4j.jul.LogManager
    - -Dlog4j.shutdownCallbackRegistry=org.apache.druid.common.config.Log4jShutdown
    - -Dlog4j.shutdownHookEnabled=true
    - -Dnet.spy.log.LoggerImpl=net.spy.memcached.compat.log.SLF4JLogger
    - -Dorg.jboss.logging.provider=slf4j
    - -Duser.timezone=UTC
    - -XX:+ExitOnOutOfMemoryError
    - -XX:MaxDirectMemorySize=2g
    - -server
  log4jConfig: |-
    <?xml version="1.0" encoding="UTF-8" ?>
    <Configuration status="WARN">
        <Appenders>
            <Console name="Console" target="SYSTEM_OUT">
                <PatternLayout pattern="%d{ISO8601} %p [%t] %c - %m%n"/>
            </Console>
        </Appenders>
        <Loggers>
            <Root level="info">
                <AppenderRef ref="Console"/>
            </Root>
        </Loggers>
    </Configuration>
  metadataStorage:
#    connector:
#      connectURI: jdbc:postgresql://druid-postgresql/druid
#      password: druid
#      user: druid
    type: postgresql
  metricDimensions: { }
  nodeSelector: { }
  nodes:
    brokers:
      autoscaling: { }
      druidPort: 8088
      env: [ ]
      envFrom: [ ]
      extraJvmOptions:
        - -Xms512m
        - -Xmx512m
      hpAutoscaler: { }
      jvmOptions: [ ]
      kind: ""
      nodeConfigMountPath: /opt/druid/conf/druid/cluster/query/broker
      nodeSelector: { }
      nodeType: broker
      podAnnotations: { }
      podLabels: { }
      replicas: 1
      resources: { }
      runtimeProperties:
        druid:
          sql:
            enable: true
      services: [ ]
      storage: { }
      unsupported: { }
      volumeClaimTemplates: { }
    cold:
      autoscaling: { }
      druidPort: 8088
      env: [ ]
      envFrom: [ ]
      extraJvmOptions:
        - -Xms512m
        - -Xmx512m
      hpAutoscaler: { }
      jvmOptions: [ ]
      kind: ""
      nodeConfigMountPath: /opt/druid/conf/druid/cluster/data/historical
      nodeSelector: { }
      nodeType: historical
      podAnnotations: { }
      podLabels: { }
      replicas: 0
      resources: { }
      runtimeProperties:
        druid:
          service: druid/cold
          server:
            priority: 0
            tier: cold
      services: [ ]
      storage:
        class: ""
        freeSpacePercent: 10
        size: ""
      unsupported: { }
      volumeClaimTemplates: { }
    coordinators:
      autoscaling: { }
      druidPort: 8088
      env: [ ]
      envFrom: [ ]
      extraJvmOptions:
        - -Xms800m
        - -Xmx800m
      hpAutoscaler: { }
      jvmOptions: [ ]
      kind: ""
      nodeConfigMountPath: /opt/druid/conf/druid/cluster/master/coordinator-overlord
      nodeSelector: { }
      nodeType: coordinator
      podAnnotations: { }
      podLabels: { }
      replicas: 1
      resources: { }
      runtimeProperties:
        druid:
          indexer:
            runner:
              capacity: 10
              javaOptsArray:
                - -Dfile.encoding=UTF-8
                - -Djava.util.logging.manager=org.apache.logging.log4j.jul.LogManager
                - -Dlog4j.shutdownCallbackRegistry=org.apache.druid.common.config.Log4jShutdown
                - -Dlog4j.shutdownHookEnabled=true
                - -Dnet.spy.log.LoggerImpl=net.spy.memcached.compat.log.SLF4JLogger
                - -Dorg.jboss.logging.provider=slf4j
                - -Duser.timezone=UTC
                - -XX:+ExitOnOutOfMemoryError
                - -XX:MaxDirectMemorySize=2g
                - -Xms512m
                - -Xmx512m
                - -server
      services: [ ]
      storage: { }
      unsupported: { }
      volumeClaimTemplates: { }
    historicals:
      autoscaling: { }
      druidPort: 8088
      env: [ ]
      envFrom: [ ]
      extraJvmOptions:
        - -Xms512m
        - -Xmx512m
      hpAutoscaler: { }
      jvmOptions: [ ]
      kind: ""
      nodeConfigMountPath: /opt/druid/conf/druid/cluster/data/historical
      nodeSelector: { }
      nodeType: historical
      podAnnotations: { }
      podLabels: { }
      replicas: 1
      resources: { }
      runtimeProperties: { }
      services: [ ]
      storage:
        class: ""
        freeSpacePercent: 10
        size: ""
      unsupported: { }
      volumeClaimTemplates: { }
    hot:
      autoscaling: { }
      druidPort: 8088
      env: [ ]
      envFrom: [ ]
      extraJvmOptions:
        - -Xms512m
        - -Xmx512m
      hpAutoscaler: { }
      jvmOptions: [ ]
      kind: ""
      nodeConfigMountPath: /opt/druid/conf/druid/cluster/data/historical
      nodeSelector: { }
      nodeType: historical
      podAnnotations: { }
      podLabels: { }
      replicas: 0
      resources: { }
      runtimeProperties:
        druid:
          service: druid/hot
          server:
            priority: 1
            tier: hot
      services: [ ]
      storage:
        class: ""
        freeSpacePercent: 10
        size: ""
      unsupported: { }
      volumeClaimTemplates: { }
    routers:
      autoscaling: { }
      # As of Druid Operator 1.3.0, port 8088 is required because it's hardcoded in the Druid operator - see
      # https://github.com/datainfrahq/druid-operator/issues/220 :
      druidPort: 8088
      env: [ ]
      envFrom: [ ]
      extraJvmOptions:
        - -Xmx512M
        - -Xms512M
      hpAutoscaler: { }
      jvmOptions: [ ]
      kind: ""
      nodeConfigMountPath: /opt/druid/conf/druid/cluster/query/router
      nodeSelector: { }
      nodeType: router
      podAnnotations: { }
      podLabels: { }
      replicas: 1
      resources: { }
      runtimeProperties:
        druid:
          router:
            managementProxy:
              enabled: true
      services: [ ]
      storage: { }
      unsupported: { }
      volumeClaimTemplates: { }
  podAnnotations:
    dummy: k8s_extension_needs_at_least_one_annotation
  podLabels: { }
  s3:
    # Configure S3 for indexing logs:
    logs:
      # Default value is the full name of the chart:
      bucket: ""
      disableAcls: true
      # Default value is the name of the chart plus `-logs` as suffix:
      prefix: ""
    # Configure S3 for data segments:
    segments:
      # Default value is the full name of the chart:
      bucket: ""
      disableAcls: true
      # Default value is the name of the chart:
      prefix: ""
  services:
    - spec:
        # Must be headless:
        clusterIP: None
  storage: { }
  tolerations: [ ]
  unsupported: { }
  volumeClaimTemplates: { }